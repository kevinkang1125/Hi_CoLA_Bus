{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Suppose model is your trained KLRegressor\n",
    "model.eval()\n",
    "\n",
    "# Target KL score\n",
    "target_kl = torch.tensor([0.2], dtype=torch.float32)\n",
    "\n",
    "# Initialize the input parameter vector (treated as features)\n",
    "# Shape must match input dimension of the model\n",
    "theta = torch.randn((1, model.net[0].in_features), requires_grad=True)\n",
    "\n",
    "# Optimizer to update the input\n",
    "optimizer = optim.Adam([theta], lr=1e-2)\n",
    "\n",
    "# Define loss as distance between predicted KL and target\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for step in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    pred_kl = model(theta)        # Forward pass through the frozen network\n",
    "    loss = criterion(pred_kl, target_kl)  # Compare with target KL\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 50 == 0 or step == 499:\n",
    "        print(f\"Step {step}: KL = {pred_kl.item():.4f}, Loss = {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Behaviour_pi import Behaviour_pi, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload model\n",
    "model = KLRegressor(input_dim=X.shape[1])\n",
    "model.load_state_dict(torch.load(\"kl_regressor.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Target value you want the model to achieve\n",
    "target_value = torch.tensor([[0.42]], dtype=torch.float32)\n",
    "\n",
    "# Initialize input vector (can also be from real data)\n",
    "optimized_input = torch.randn((1, X.shape[1]), requires_grad=True)\n",
    "\n",
    "# Optimizer for input\n",
    "input_optimizer = torch.optim.Adam([optimized_input], lr=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Store optimization trace\n",
    "loss_trace = []\n",
    "output_trace = []\n",
    "\n",
    "for step in range(300):\n",
    "    input_optimizer.zero_grad()\n",
    "    output = model(optimized_input)\n",
    "    loss = loss_fn(output, target_value)\n",
    "    loss.backward()\n",
    "    input_optimizer.step()\n",
    "\n",
    "    # Store values\n",
    "    loss_trace.append(loss.item())\n",
    "    output_trace.append(output.item())\n",
    "\n",
    "    if step % 50 == 0 or step == 299:\n",
    "        print(f\"Step {step:03d} | Loss: {loss.item():.6f} | Output: {output.item():.4f}\")\n",
    "\n",
    "# === Plot Optimization Trajectory ===\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Loss vs. step\n",
    "ax[0].plot(loss_trace, label='Loss')\n",
    "ax[0].set_title(\"Policy Gradient-style Input Optimization\")\n",
    "ax[0].set_xlabel(\"Step\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].grid(True)\n",
    "\n",
    "# Output vs. step\n",
    "ax[1].plot(output_trace, label='Predicted Output', color='orange')\n",
    "ax[1].axhline(y=target_value.item(), color='r', linestyle='--', label='Target')\n",
    "ax[1].set_xlabel(\"Step\")\n",
    "ax[1].set_ylabel(\"Model Output\")\n",
    "ax[1].grid(True)\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multiagent_Search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
